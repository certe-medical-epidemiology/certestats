% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machine_learning.R
\name{machine_learning}
\alias{machine_learning}
\alias{ml_xg_boost}
\alias{ml_decision_trees}
\alias{ml_random_forest}
\alias{ml_neural_network}
\alias{ml_nearest_neighbour}
\alias{ml_linear_regression}
\alias{ml_logistic_regression}
\alias{confusion_matrix.certestats_ml}
\alias{predict.certestats_ml}
\alias{apply_model_to}
\alias{feature_importances}
\alias{feature_importance_plot}
\alias{roc_plot}
\alias{gain_plot}
\alias{tree_plot}
\alias{correlation_plot}
\alias{get_metrics}
\alias{get_accuracy}
\alias{get_kappa}
\alias{get_recipe}
\alias{get_specification}
\alias{get_rows_testing}
\alias{get_rows_training}
\alias{get_original_data}
\alias{get_roc_data}
\alias{get_coefficients}
\alias{get_model_variables}
\alias{get_variable_weights}
\alias{tune_parameters}
\alias{check_testing_predictions}
\alias{autoplot.certestats_ml}
\alias{autoplot.certestats_feature_importances}
\alias{autoplot.certestats_tuning}
\title{Create a Machine Learning (ML) Model}
\usage{
ml_xg_boost(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "xgboost",
  mode = c("classification", "regression", "unknown"),
  trees = 15,
  ...
)

ml_decision_trees(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "rpart",
  mode = c("classification", "regression", "unknown"),
  tree_depth = 30,
  ...
)

ml_random_forest(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "ranger",
  mode = c("classification", "regression", "unknown"),
  trees = 500,
  ...
)

ml_neural_network(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "nnet",
  mode = c("classification", "regression", "unknown"),
  penalty = 0,
  epochs = 100,
  ...
)

ml_nearest_neighbour(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "kknn",
  mode = c("classification", "regression", "unknown"),
  neighbors = 5,
  weight_func = "triangular",
  ...
)

ml_linear_regression(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "lm",
  mode = "regression",
  ...
)

ml_logistic_regression(
  .data,
  outcome,
  predictors = everything(),
  training_fraction = 0.75,
  strata = NULL,
  na_threshold = 0.01,
  correlation_threshold = 0.9,
  centre = TRUE,
  scale = TRUE,
  engine = "glm",
  mode = "classification",
  penalty = 0.1,
  ...
)

\method{confusion_matrix}{certestats_ml}(data, ...)

\method{predict}{certestats_ml}(object, new_data, type = NULL, ...)

apply_model_to(
  object,
  new_data,
  add_certainty = TRUE,
  only_prediction = FALSE,
  correct_mistakes = TRUE,
  impute_algorithm = "mice",
  ...
)

feature_importances(object, ...)

feature_importance_plot(object, ...)

roc_plot(object, ...)

gain_plot(object, ...)

tree_plot(object, ...)

correlation_plot(
  data,
  add_values = TRUE,
  cols = everything(),
  correlation_threshold = 0.9
)

get_metrics(object)

get_accuracy(object)

get_kappa(object)

get_recipe(object)

get_specification(object)

get_rows_testing(object)

get_rows_training(object)

get_original_data(object)

get_roc_data(object)

get_coefficients(object)

get_model_variables(object)

get_variable_weights(object)

tune_parameters(object, ..., only_params_in_model = FALSE, levels = 5, k = 10)

check_testing_predictions(object)

\method{autoplot}{certestats_ml}(object, plot_type = "roc", ...)

\method{autoplot}{certestats_feature_importances}(object, ...)

\method{autoplot}{certestats_tuning}(object, type = c("marginals", "parameters", "performance"), ...)
}
\arguments{
\item{.data}{Data set to train}

\item{outcome}{Outcome variable, also called the \emph{response variable} or the \emph{dependent variable}; the variable that must be predicted. The value will be evaluated in \code{\link[dplyr:select]{select()}} and thus supports the \code{tidyselect} language. In case of classification prediction, this variable will be coerced to a \link{factor}.}

\item{predictors}{Explanatory variables, also called the \emph{predictors} or the \emph{independent variables}; the variables that are used to predict \code{outcome}. These variables will be transformed using \code{\link[=as.double]{as.double()}} (\link{factor}s will be transformed to \link{character}s first). This value defaults to \code{\link[tidyselect:everything]{everything()}} and supports the \code{tidyselect} language.}

\item{training_fraction}{Fraction of rows to be used for \emph{training}, defaults to 75\%. The rest will be used for \emph{testing}. If given a number over 1, the number will be considered to be the required number of rows for \emph{training}.}

\item{strata}{A variable in \code{data} (single character or name) used to conduct
stratified sampling. When not \code{NULL}, each resample is created within the
stratification variable. Numeric \code{strata} are binned into quartiles.}

\item{na_threshold}{Maximum fraction of \code{NA} values (defaults to \code{0.01}) of the \code{predictors} before they are removed from the model, using \code{\link[recipes:step_select]{recipes::step_select()}}}

\item{correlation_threshold}{A value (default 0.9) to indicate the correlation threshold. Predictors with a correlation higher than this value with be removed from the model, using \code{\link[recipes:step_corr]{recipes::step_corr()}}}

\item{centre}{A \link{logical} to indicate whether the \code{predictors} should be transformed so that their mean will be \code{0}, using \code{\link[recipes:step_center]{recipes::step_center()}}. Binary columns will be skipped.}

\item{scale}{A \link{logical} to indicate whether the \code{predictors} should be transformed so that their standard deviation will be \code{1}, using \code{\link[recipes:step_scale]{recipes::step_scale()}}. Binary columns will be skipped.}

\item{engine}{\R package or function name to be used for the model, will be passed on to \code{\link[parsnip:set_engine]{parsnip::set_engine()}}}

\item{mode}{Type of predicted value - defaults to \code{"classification"}, but can also be \code{"unknown"} or \code{"regression"}}

\item{trees}{An integer for the number of trees contained in
the ensemble.}

\item{...}{Arguments to be passed on to the \code{parsnip} functions, see \emph{Model Functions}.

For the \code{\link[=tune_parameters]{tune_parameters()}} function, these must be \code{dials} package calls, such as \code{dials::trees()} (see Examples).

For \code{\link[parsnip:predict.model_fit]{predict()}}, these must be arguments passed on to \code{\link[parsnip:predict.model_fit]{parsnip::predict.model_fit()}}}

\item{tree_depth}{An integer for maximum depth of the tree.}

\item{penalty}{A non-negative number representing the total
amount of regularization (specific engines only).}

\item{epochs}{An integer for the number of training iterations.}

\item{neighbors}{A single integer for the number of neighbors
to consider (often called \code{k}). For \pkg{kknn}, a value of 5
is used if \code{neighbors} is not specified.}

\item{weight_func}{A \emph{single} character for the type of kernel function used
to weight distances between samples. Valid choices are: \code{"rectangular"},
\code{"triangular"}, \code{"epanechnikov"}, \code{"biweight"}, \code{"triweight"},
\code{"cos"}, \code{"inv"}, \code{"gaussian"}, \code{"rank"}, or \code{"optimal"}.}

\item{object, data}{outcome of machine learning model}

\item{new_data}{A rectangular data object, such as a data frame.}

\item{type}{A single character value or \code{NULL}. Possible values
are \code{"numeric"}, \code{"class"}, \code{"prob"}, \code{"conf_int"}, \code{"pred_int"},
\code{"quantile"}, \code{"time"}, \code{"hazard"}, \code{"survival"}, or \code{"raw"}. When \code{NULL},
\code{predict()} will choose an appropriate value based on the model's mode.}

\item{add_certainty}{a \link{logical} to indicate whether certainties should be added to the output \link{data.frame}}

\item{only_prediction}{a \link{logical} to indicate whether predictions must be returned as \link{vector}, otherwise returns a \link{data.frame}}

\item{correct_mistakes}{a \link{logical} to indicate whether missing variables and missing values should be added to \code{new_data}}

\item{impute_algorithm}{the algorithm to use in \code{\link[=impute]{impute()}} if \code{correct_mistakes = TRUE}. Can be \code{"mice"} (default) for the \link[mice:mice]{Multivariate Imputations by Chained Equations (MICE) algorithm}, or \code{"single-point"} for a trained median.}

\item{add_values}{a \link{logical} to indicate whether values must be printed in the tiles}

\item{cols}{columns to use for correlation plot, defaults to \code{\link[dplyr:reexports]{everything()}}}

\item{only_params_in_model}{a \link{logical} to indicate whether only parameters in the model should be tuned}

\item{levels}{An integer for the number of values of each parameter to use
to make the regular grid. \code{levels} can be a single integer or a vector of
integers that is the same length as the number of parameters in \code{...}.
\code{levels} can be a named integer vector, with names that match the id values
of parameters.}

\item{k}{The number of partitions of the data set}

\item{plot_type}{the plot type, can be \code{"roc"} (default), \code{"gain"}, \code{"lift"} or \code{"pr"}. These functions rely on \code{\link[yardstick:roc_curve]{yardstick::roc_curve()}}, \code{\link[yardstick:gain_curve]{yardstick::gain_curve()}}, \code{\link[yardstick:lift_curve]{yardstick::lift_curve()}} and \code{\link[yardstick:pr_curve]{yardstick::pr_curve()}} to construct the curves.}
}
\value{
A machine learning model of class \code{certestats_ml} / ... / \code{model_fit}.
}
\description{
These functions can be used to create a machine learning model based on different 'engines' and to generalise predicting outcomes based on such models. These functions are wrappers around \code{tidymodels} packages (especially \href{https://parsnip.tidymodels.org}{\code{parsnip}}, \href{https://recipes.tidymodels.org}{\code{recipes}}, \href{https://rsample.tidymodels.org}{\code{rsample}}, \href{https://tune.tidymodels.org}{\code{tune}}, and \href{https://yardstick.tidymodels.org}{\code{yardstick}}) created by RStudio.
}
\details{
To predict \strong{regression} (numeric values), the function \code{\link[=ml_logistic_regression]{ml_logistic_regression()}} cannot be used.

To predict \strong{classifications} (character values), the function \code{\link[=ml_linear_regression]{ml_linear_regression()}} cannot be used.

The workflow of the \verb{ml_*()} functions is basically like this (thus saving a lot of \code{tidymodels} functions to type):

\preformatted{
                       .data
                         |
               rsample::initial_split()
                     /        \
     rsample::training() rsample::testing()
             |                |
       recipe::recipe()       |
             |                |
      recipe::step_corr()     |
             |                |
     recipe::step_center()    |
             |                |
      recipe::step_scale()    |
             |                |
        recipe::prep()        |
         /           \        |
recipes::bake()       recipes::bake()
       |                      |
generics::fit()      yardstick::metrics()
       |                      |
    output            attributes(output)
}

The \code{\link[parsnip:predict.model_fit]{predict()}} function can be used to fit a model on a new data set. Its wrapper \code{\link[=apply_model_to]{apply_model_to()}} works in the same way, but can also detect and fix missing variables, missing data points, and data type differences between the trained data and the input data.

Use \code{\link[=feature_importances]{feature_importances()}} to get the importance of all features/variables. Use \code{\link[=autoplot]{autoplot()}} afterwards to plot the results. These two functions are combined in \code{\link[=feature_importance_plot]{feature_importance_plot()}}.

Use \code{\link[=correlation_plot]{correlation_plot()}} to plot the correlation between all variables, even characters. If the input is a \code{certestats} ML model, the training data of the model will be plotted.

Use the \code{\link[=get_model_variables]{get_model_variables()}} function to return a zero-row \link{data.frame} with the variables that were used for training, even before the recipe steps.

Use the \code{\link[=get_variable_weights]{get_variable_weights()}} function to determine the (rough) estimated weights of each variable in the model. This is not as reliable as retrieving coefficients, but it does work for any model. The weights are determined by running the model over all the highest and lowest values of each variable in the trained data. The function returns a data set with 1 row, of which the values sum up to 1.

Use the \code{\link[=tune_parameters]{tune_parameters()}} function to analyse tune parameters of any \verb{ml_*()} function. Without any parameters manually defined, it will try to tune all parameters of the underlying ML model. The tuning will be based on a \link[rsample:vfold_cv]{K-fold cross-validation}, of which the number of partitions can be set with \code{k}. The number of \code{levels} will be used to split the range of the parameters. For example, a range of 1-10 with \code{levels = 2} will lead to \verb{[1, 10]}, while \code{levels = 5} will lead to \verb{[1, 3, 5, 7, 9]}. The resulting \link{data.frame} will be sorted from best to worst. These results can also be plotted using \code{\link[=autoplot]{autoplot()}}.

The \code{\link[=check_testing_predictions]{check_testing_predictions()}} function combines the data used for testing from the original data with its predictions, so the original data can be reviewed per prediction.

Use \code{\link[=autoplot]{autoplot()}} on a model to plot the receiver operating characteristic (ROC) curve, the gain curve, the lift curve, or the precision-recall (PR) curve. For the ROC curve, the (overall) area under the curve (AUC) will be printed as subtitle.
}
\section{Attributes}{

The \verb{ml_*()} functions return the following \link[base:attributes]{attributes}:
\itemize{
\item \code{properties}: a \link{list} with model properties: the ML function, engine package, training size, testing size, strata size, mode, and the different ML function-specific properties (such as \code{tree_depth} in \code{\link[=ml_decision_trees]{ml_decision_trees()}})
\item \code{recipe}: a \link[recipes:recipe]{recipe} as generated with \code{\link[recipes:prep]{recipes::prep()}}, to be used for training and testing
\item \code{data_original}: a \link{data.frame} containing the original data, possibly without invalid strata
\item \code{data_structure}: a \link{data.frame} containing the original data structure (only trained variables) with zero rows
\item \code{data_means}: a \link{data.frame} containing the means of the original data (only trained variables)
\item \code{data_training}: a \link{data.frame} containing the training data of \code{data_original}
\item \code{data_testing}: a \link{data.frame} containing the testing data of \code{data_original}
\item \code{rows_training}: an \link{integer} vector of rows used for training in \code{data_original}
\item \code{rows_testing}: an \link{integer} vector of rows used for training in \code{data_original}
\item \code{predictions}: a \link{data.frame} containing predicted values based on the testing data
\item \code{metrics}: a \link{data.frame} with model metrics as returned by \code{\link[yardstick:metrics]{yardstick::metrics()}}
\item \code{correlation_threshold}: a \link{logical} indicating whether \code{\link[recipes:step_corr]{recipes::step_corr()}} has been applied
\item \code{centre}: a \link{logical} indicating whether \code{\link[recipes:step_center]{recipes::step_center()}} has been applied
\item \code{scale}: a \link{logical} indicating whether \code{\link[recipes:step_scale]{recipes::step_scale()}} has been applied
}
}

\section{Model Functions}{

These are the called functions from the \code{parsnip} package. Arguments set in \code{...} will be passed on to these \code{parsnip} functions:
\itemize{
\item \code{ml_decision_trees}: \code{\link[parsnip:decision_tree]{parsnip::decision_tree()}}
\item \code{ml_linear_regression}: \code{\link[parsnip:linear_reg]{parsnip::linear_reg()}}
\item \code{ml_logistic_regression}: \code{\link[parsnip:logistic_reg]{parsnip::logistic_reg()}}
\item \code{ml_neural_network}: \code{\link[parsnip:mlp]{parsnip::mlp()}}
\item \code{ml_nearest_neighbour}: \code{\link[parsnip:nearest_neighbor]{parsnip::nearest_neighbor()}}
\item \code{ml_random_forest}: \code{\link[parsnip:rand_forest]{parsnip::rand_forest()}}
\item \code{ml_xg_boost}: \code{\link[parsnip:xgb_train]{parsnip::xgb_train()}}
}
}

\examples{
# 'esbl_tests' is an included data set, see ?esbl_tests
print(esbl_tests, n = 5)

esbl_tests |> correlation_plot(add_values = FALSE) # red will be removed from model

# predict ESBL test outcome based on MICs using 2 different models
model1 <- esbl_tests |> ml_xg_boost(esbl, where(is.double))
model2 <- esbl_tests |> ml_decision_trees(esbl, where(is.double))


# Assessing A Model ----------------------------------------------------

model1 |> get_metrics()
model2 |> get_metrics()

model1 |> confusion_matrix()

# a correlation plot of a model shows the training data
model1 |> correlation_plot(add_values = FALSE)

model1 |> feature_importances()
model1 |> feature_importances() |> autoplot()
model2 |> feature_importance_plot()

# decision trees can also have a tree plot
model2 |> tree_plot()


# Applying A Model -----------------------------------------------------
 
# simply use base R `predict()` to apply a model:
model1 |> predict(esbl_tests)

# but apply_model_to() contains more info and can apply corrections:
model1 |> apply_model_to(esbl_tests)
model1 |> apply_model_to(esbl_tests[, 1:15])
esbl_tests2 <- esbl_tests
esbl_tests2[2, "CIP"] <- NA
esbl_tests2[5, "AMC"] <- NA
# with XGBoost, nothing will be changed (it can correct for missings):
model1 |> apply_model_to(esbl_tests2)
# with random forest (or others), missings will be imputed:
model2 |> apply_model_to(esbl_tests2)


# Tuning A Model -------------------------------------------------------
 
# tune the parameters of a model (will take some time)
tuning <- model2 |> 
  tune_parameters(k = 5, levels = 3)
autoplot(tuning)

# tuning analysis by specifying (some) parameters
iris |> 
  ml_xg_boost(Species) |> 
  tune_parameters(mtry = dials::mtry(range = c(1, 3)),
                  trees = dials::trees())


# Practical Example #1 --------------------------------------------------

# this is what iris data set looks like:
head(iris)
# create a model to predict the species:
iris_model <- iris |> ml_xg_boost(Species)
iris_model_rf <- iris |> ml_random_forest(Species)
# is it a bit reliable?
get_metrics(iris_model)

# now try to predict species from an arbitrary data set:
to_predict <- data.frame(Sepal.Length = 5,
                         Sepal.Width = 3,
                         Petal.Length = 1.5,
                         Petal.Width = 0.5)
to_predict

# should be 'setosa' in the 'predicted' column with huge certainty:
iris_model |> apply_model_to(to_predict)

# which variables are generally important (only trained variables)?
iris_model |> feature_importances()

# how would the model do without the 'Sepal.Length' column?
to_predict <- to_predict[, c("Sepal.Width", "Petal.Width", "Petal.Length")]
to_predict
iris_model |> apply_model_to(to_predict)

# now compare that with a random forest model that requires imputation:
iris_model_rf |> apply_model_to(to_predict)

# the certainly is very different.


# Practical Example #2 -------------------------------------------------

# this example shows plotting methods for a model

# train model to predict genus based on MICs:
genus <- esbl_tests |> ml_xg_boost(genus, everything())
genus |> get_metrics()
genus |> feature_importance_plot()
genus |> autoplot()
genus |> autoplot(plot_type = "gain")
genus |> autoplot(plot_type = "pr")
}
